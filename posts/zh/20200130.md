# Rust 编译模型之殇

*发表于 2020.01.30  作者：Brian Anderson* 


![img1](../../imgs/rust-compile-time-adventures.png)

*Rust 编译缓慢的根由在于语言的设计。*

我的意思并非是此乃 Rust 语言的*设计目标*。正如语言设计者们相互争论时经常说的那样，编程语言的设计总是充满了各种权衡。其中最主要的权衡就是：**运行时性能** 和 **编译时性能**。而 Rust 团队几乎总是选择运行时而非编译时。

因此，Rust 编译时间很慢。这有点让人恼火，因为 Rust 在其他方面的表现都非常好，唯独 Rust 编译时间却表现如此糟糕。

## Rust 与 TiKV 的编译时冒险：第1集

在 [PingCAP](https://pingcap.com/)，我们基于 Rust 开发了分布式存储系统 [TiKV](https://github.com/tikv/tikv/) 。然而它的编译速度慢到足以让公司里的许多人不愿使用 Rust。我最近花了一些时间，与TiKV团队及其社区中的其他几人一起调研了 TiKV 编译时间缓慢的问题。

通过这一系列博文，我将会讨论在这个过程中的收获：

* 为什么 Rust 编译那么慢，或者说让人感觉那么慢；
* Rust 的发展如何造就了编译时间的缓慢；
* 编译时用例；
* 我们测量过的，以及想要测量但还没有或者不知道如何测量的项目；
* 改善编译时间的一些思路；
* 事实上未能改善编译时间的思路；
* TiKV 编译时间的历史演进
* 有关如何组织 Rust 项目可加速编译的建议；
* 最近和未来，上游将对编译时间的改进；

---

本集包括如下内容:

*  [PingCAP的阴影：TiKV 编译次数 “余额不足”](https://pingcap.com/blog/rust-compilation-model-calamity/#the-spectre-of-poor-rust-compile-times-at-pingcap) 
*  [概览: TiKV 编译时冒险历程](https://pingcap.com/blog/rust-compilation-model-calamity/#preview-the-tikv-compile-time-adventure-so-far) 
*  [造就编译时间缓慢的 Rust 设计](https://pingcap.com/blog/rust-compilation-model-calamity/#rusts-designs-for-poor-compilation-time) 	   
    *  [Rust 的自举](https://pingcap.com/blog/rust-compilation-model-calamity/#bootstrapping-rust) 
	*  [（非）良性循环](https://pingcap.com/blog/rust-compilation-model-calamity/#unvirtuous-cycles) 
	*  [运行时优先于编译时的早期决策](https://pingcap.com/blog/rust-compilation-model-calamity/#early-decisions-that-favored-run-time-over-compile-time) 
*  [改善 Rust 编译时间的最新进展](https://pingcap.com/blog/rust-compilation-model-calamity/#recent-work-on-rust-compile-times) 
*  [下集预告](https://pingcap.com/blog/rust-compilation-model-calamity/#in-the-next-episode) 
*  [鸣谢](https://pingcap.com/blog/rust-compilation-model-calamity/#thanks) 

## PingCAP的阴影：TiKV 编译次数 “余额不足”

At [PingCAP](https://pingcap.com/en/) , my colleagues use Rust to write  [TiKV](https://github.com/tikv/tikv/) , the storage node of  [TiDB](https://github.com/pingcap/tidb) , our distributed database. They do this because they want this most important node in the system to be fast and reliable by construction, at least to the greatest extent reasonable.

在 [PingCAP](https://pingcap.com/en/)，我的同事用Rust写 [TiKV](https://github.com/tikv/tikv/)。它是我们的分布式数据库 [TiDB](https://github.com/pingcap/tidb) 的存储节点。采用这样的架构，是因为他们希望该系统中作为最重要的节点，能被构造的快速且可靠，至少是在一个最大程度的合理范围内。（译注：通常情况下人们认为快和可靠是很难同时做到的，人们只能在设计/构造的时候做出权衡。选择 Rust 是为了尽可能让 TiKV 能够在尽可能合理的情况下去提高它的速度和可靠性。）

It was mostly a great decision, and most people internally are mostly happy about it.

这是一个很棒的决定，并且团队内大多数人对此都非常满意。

But many complain about how long it takes to build. For some, a full rebuild might take 15 minutes in development mode, and 30 minutes in release mode. To developers of large systems projects, this might not sound so bad, but it’s much slower than what many developers expect out of modern programming environments. TiKV is a relatively large Rust codebase, with 2 million lines of Rust. In comparison, Rust itself contains over 3 million lines of Rust, and  [Servo](https://github.com/servo/servo)  contains 2.7 million (see  [full line counts here](https://gist.github.com/brson/31b6f8c5467b050779ce9aa05d41aa84) ).

但是许多人抱怨构建的时间太长。有时，在开发模式下完全重新构建需要花费 15 分钟，而在发布模式则需要 30 分钟。对于大型系统项目的开发者而言，这看上去可能并不那么糟糕。但是它与许多开发者从现代的开发环境中期望得到的速度相比则慢了很多。TiKV 是一个相当巨大的代码库，它拥有 200 万行 Rust 代码。相比之下，Rust 自身包含超过 300 万行 Rust 代码，而 [Servo](https://github.com/servo/servo)  包含 270 万行（请参阅 [此处的完整行数统计](https://gist.github.com/brson/31b6f8c5467b050779ce9aa05d41aa84) ）。

Other nodes in TiDB are written in Go, which of course comes with a different set of advantages and disadvantages from Rust. Some of the Go developers at PingCAP resent having to wait for the Rust components to build. They are used to a rapid build-test cycle.

TiDB 中的其他节点是用 Go 编写的，当然，Go 与 Rust 有不同的优点和缺点。PingCAP 的一些 Go 开发人员对不得不等待 Rust 组件的构建而表示不满。因为他们习惯于快速的构建-测试迭代。

Rust developers, on the other hand, are used to taking a lot of coffee breaks (or tea, cigarettes, sobbing, or whatever as the case may be — Rust developers have the spare time to nurse their demons).

而另一边，Rust 开发人员却在那喝咖啡休息，或者喝茶、抽烟，或者诉苦，视情况而定。Rust开发人员有多余的时间（Go 开发者却没有）来跨越内心的“阴影（译注：据说，TiKV 一天只有 24 次编译机会，用一次少一次）”。

## 概览: TiKV 编译时冒险历程

The first entry in this series is just a story about the history of Rust with respect to compilation time. Since it might take several more entries before we dive into concrete technical details of what we’ve done with TiKV’s compile times, here’s a pretty graph to capture your imagination, without comment.

本系列的第一篇文章只是关于 Rust 在编译时间方面的历史演进。因为在我们深入研究TiKV编译时间的具体技术细节之前，可能需要更多的篇章。所以，这里先有一个漂亮的无说明的图表来捕捉你的想象力。

![img2](../../imgs/rust-compile-times-tikv.svg)

* TiKV 的 Rust 编译时间*

## 造就编译时间缓慢的 Rust 设计

Rust was designed for slow compilation times.

Rust 编译缓慢的根由在于语言的设计。

I mean, that wasn’t *the goal*. As is often cautioned in debates among their designers, programming language design is full of tradeoffs. One of those fundamental tradeoffs is *run-time performance* vs. *compile-time performance*, and the Rust team nearly always (if not always) chose run-time over compile-time.

我的意思并非是此乃 Rust 语言的*设计目标*。正如语言设计者们相互争论时经常说的那样，编程语言的设计总是充满了各种权衡。其中最主要的权衡就是：**运行时性能** 和 **编译时性能**。而 Rust 团队几乎总是选择运行时而非编译时。

The intentional run-time/compile-time tradeoff isn’t the only reason Rust compile times are horrific, but it’s a big one. There are also language designs that are not crucial for run-time performance, but accidentally bad for compile-time performance. The Rust compiler was also implemented in ways that inhibit compile-time performance.

刻意的运行时/编译时权衡不是 Rust 编译时间差劲的唯一原因，但这是一个大问题。还有一些语言设计对运行时性能并不是至关重要，但却意外地有损于编译时性能。Rust编译器的实现方式也抑制了编译时性能。

So there are intrinsic language-design reasons and accidental language-design reasons for Rust’s bad compile times. Those mostly can’t be fixed ever, although they may be mitigated by compiler improvements, design patterns, and language evolution. There are also accidental compiler-architecture reasons for Rust’s bad compile times, which can generally be fixed through enormous engineering effort and time.

所以，Rust 编译时间的差劲，既是刻意为之的造就，又有出于设计之外的原因。尽管编译器的改善、设计模式和语言的发展可能会缓解这些问题，但这些问题大多无法得到解决。还有一些偶然的编译器架构原因导致了 Rust 的编译时间很慢，这些需要通过大量的工程时间和精力来修复。

If fast compilation time was not a core Rust design principle, what were Rust’s core design principles? Here are a few:

如果迅速地编译不是 Rust 的核心设计原则，那么 Rust 的核心设计原则是什么呢？下面列出几个核心设计原则：

* *Practicality* — it should be a language that can be and is used in the real world.
* *Pragmatism* — it should admit concessions to human usability and integration into systems as they exist today.
* *Memory-safety* — it must enforce memory safety, and not admit segmentation faults and other such memory-access violations.
* *Performance* — it must be in the same performance class as C++.
* *Concurrency* — it must provide modern solutions to writing concurrent code.

* *实用性（Practicality）* — 它应该是一种可以在现实世界中使用的语言。
* *务实（Pragmatism）* — 它应该是符合人性化体验，并且能与现有系统方便集成的语言。
* *内存安全性（Memory-safety）* — 它必须加强内存安全，不允许出现段错误和其他类似的内存访问违规操作。
* *高性能（Performance）* — 它必须拥有能和 C++ 比肩的性能。
* *高并发（Concurrency）* — 它必须为编写并发代码提供现代化的解决方案。

But it’s not like the designers didn’t put /any/ consideration into fast compile times. For example, for any analysis Rust needs to do, the team tried to ensure reasonable bounds on computational complexity. Rust’s design history though is one of increasingly being sucked into a swamp of poor compile-time performance.

但这并不是说设计者没有为编译速度做*任何*考虑。例如，对于 Rust 需要做的任何分析，团队试图确保计算复杂性的合理界限。然而，Rust 的设计历史也是其一步步陷入糟糕的编译时性能沼泽的历史。

Story time.

讲故事的时间到了。

## Rust 的自举

I don’t remember when I realized that Rust’s bad compile times were a strategic problem for the language, potentially a fatal mistake in the face of competition from future low-level programming languages. For the first few years, hacking almost entirely on the Rust compiler itself, I wasn’t too concerned, and I don’t think most of my peers were either. I mostly remember that Rust compile time was always bad, and like, whatever, I can deal with that.

When I worked daily on the Rust compiler, it was common for me to have at least three copies of the repository on the computer, hacking on one while all the others were building and testing. I would start building workspace 1, switch terminals, remember what’s going on over here in workspace 2, hack on that for a while, start building in workspace 2, switch terminals, etc. Little flow, constant context switching.
This was (and probably is) typical of other Rust developers too. I still do the same thing hacking on TiKV today.

So, historically, how bad have Rust compile times been? A simple barometer here is to see how Rust’s self-hosting times have changed over the years, which is the time it takes Rust to build itself. Rust building itself is not directly comparable to Rust building other projects, for a variety of reasons, but I think it will be illustrative.

The  [first Rust compiler](https://gist.github.com/brson/31b6f8c5467b050779ce9aa05d41aa84/edit) , from 2010, called rustboot, was written in OCaml, and it’s ultimate purpose was to build a second compiler, rustc, written in Rust, and begin the self-hosting bootstrap cycle. In addition to being written in Rust, rustc would also use  [LLVM](https://llvm.org/)  as its backend for generating machine code, instead of rustboot’s hand-written x86 code-generator.

Rust needed to become self-hosting as a means of “dog-fooding” the language — writing the Rust compiler in Rust meant that the Rust authors needed to use their own language to write practical software early in the language design process. It was hoped that self-hosting could lead to a useful and practical language.

The first time Rust built itself was on April 20, 2011.  [It took one hour](https://mail.mozilla.org/pipermail/rust-dev/2011-April/000330.html) , which was a laughably long time. At least it was back then.

That first super-slow bootstrap was an anomaly of bad code-generation and other easily fixable early bugs (probably, I don’t exactly recall). rustc’s performance quickly improved, and Graydon quickly  [threw away the old rustboot compiler](https://github.com/rust-lang/rust/commit/6997adf76342b7a6fe03c4bc370ce5fc5082a869)  since there was nowhere near enough manpower and motivation to maintain parallel implementations.

This is where the long, gruelling history of Rust’s tragic compile times began, 11 months after it was initially released in June 2010.

*Note:*

I wanted to share historic self-hosting times here, but after many hours and obstacles attempting to build Rust revisions from 2011, I finally gave up and decided I just had to publish this piece without them. Instead, here are some madeup numbers:

* /7 femto-bunnies/ - rustboot building Rust prior to being retired
* /49 kilo-hamsters/ - rustc building Rust immediately after rustboot’s retirement
* /188 giga-sloths/ - rustc building Rust in 2020

Anyway, last time I bootstrapped Rust a few months ago, it took over five hours.

The Rust language developers became acclimated to Rust’s poor self-hosting times and failed to recognize or address the severity of the problem of bad compile times during Rust’s crucial early design phase.

## (Un)virtuous cycles

In the Rust project, we like processes that reinforce and build upon themselves. This is one of the keys to Rust’s success, both as a language and a community.
As an obvious, hugely-successful example, consider  [Servo](https://github.com/servo/servo) . Servo is a web browser built in Rust, and Rust was created with the explicit purpose of building Servo. Rust and Servo are sister-projects. They were created by the same team (initially), at roughly the same time, and they evolved together. Not only was Rust built to create Servo, but Servo was built to inform the design of Rust.
The initial few years of both projects were extremely difficult, with both projects evolving in parallel. The often-used metaphor of the  [Ship of Theseus](https://en.wikipedia.org/wiki/Ship_of_Theseus)  is apt - we were constantly rebuilding Rust in order to sail the seas of Servo. There is no doubt that the experience of building Servo with Rust while simultaneously building the language itself led directly to many of the good decisions that make Rust the practical language it is.
Here are some cursory examples of the Servo-Rust feedback loop:
* Labeled break and continue  [was implemented in order to auto-generate an HTML parser](https://github.com/rust-lang/rust/issues/2216) .
* Owned closures  [were implemented after analyzing closure usage in Servo](https://github.com/rust-lang/rust/issues/2549#issuecomment-19588158) .
* External function calls used to be considered safe.  [This changed in part due to experience in Servo](https://github.com/rust-lang/rust/issues/2628#issuecomment-9384243) .
* The migration from green-threading to native threading was informed by the experience of building Servo, observing the FFI overhead of Servo’s SpiderMonkey integration, and profiling “hot splits”, where the green thread stacks needed to be expanded and contracted.
The co-development of Rust and Servo created a  [virtuous cycle](https://en.wikipedia.org/wiki/Virtuous_circle_and_vicious_circle)  that allowed both projects to thrive. Today, Servo components are deeply integrated into Firefox, ensuring that Rust cannot die while Firefox lives.
Mission accomplished.

![img3](../../imgs/rust-compile-mission-completed.png)

The previously-mentioned early self-hosting was similarly crucial to Rust's design, making Rust a superior language for building Rust compilers. Likewise, Rust and  [WebAssembly](https://webassembly.org/)  were developed in close collaboration (the author of  [Emscripten](https://github.com/emscripten-core/emscripten) , the author of  [Cranelift](https://github.com/CraneStation/cranelift) , and I had desks next to each other for years), making WASM an excellent platform for running Rust, and Rust well-suited to target WASM.
Sadly there was no such reinforcement to drive down Rust compile times. The opposite is probably true — the more Rust became known as a /fast/ language, the more important it was to be /the fastest/ language. And, the more Rust's developers got used to developing their Rust projects across multiple branches, context switching between builds, the less pressure was felt to address compile times.
This only really changed once Rust 1.0 was released in 2015 and started to receive wider use.
For years Rust  [slowly boiled](https://en.wikipedia.org/wiki/Boiling_frog)  in its own poor compile times, not realizing how bad it had gotten until it was too late. It was 1.0. Those decisions were locked in.
Too many tired metaphors in this section. Sorry about that.
## Early decisions that favored run-time over compile-time
If Rust is designed for poor compile time, then what are those designs specifically? I describe a few briefly here. The next episode in this series will go into further depth. Some have greater compile-time impact than others, but I assert that all of them cause more time to be spent in compilation than alternative designs.
Looking at some of these in retrospect, I am tempted to think that “well, of course Rust /must/ have feature /foo/", and it's true that Rust would be a completely different language without many of these features. However, language designs are tradeoffs and none of these were predestined to be part of Rust.
* /Borrowing/ — Rust's defining feature. Its sophisticated pointer analysis spends compile-time to make run-time safe.

* /Monomorphization/ — Rust translates each generic instantiation into its own machine code, creating code bloat and increasing compile time.

* /Stack unwinding/ — stack unwinding after unrecoverable exceptions traverses the callstack backwards and runs cleanup code. It requires lots of compile-time book-keeping and code generation.

* /Build scripts/ — build scripts allow arbitrary code to be run at compile-time, and pull in their own dependencies that need to be compiled. Their unknown side-effects and unknown inputs and outputs limit assumptions tools can make about them, which e.g. limits caching opportunities.

* /Macros/ — macros require multiple passes to expand, expand to often surprising amounts of hidden code, and impose limitations on partial parsing. Procedural macros have negative impacts similar to build scripts.

* /LLVM backend/ — LLVM produces good machine code, but runs relatively slowly.

* /Relying too much on the LLVM optimizer/ — Rust is well-known for generating a large quantity of LLVM IR and letting LLVM optimize it away. This is exacerbated by duplication from monomorphization.

* /Split compiler/package manager/ — although it is normal for languages to have a package manager separate from the compiler, in Rust at least this results in both cargo and rustc having imperfect and redundant information about the overall compilation pipeline. As more parts of the pipeline are short-circuited for efficiency, more metadata needs to be transferred between instances of the compiler, mostly through the filesystem, which has overhead.

* /Per-compilation-unit code-generation/ — rustc generates machine code each time it compiles a crate, but it doesn't need to — with most Rust projects being statically linked, the machine code isn't needed until the final link step. There may be efficiencies to be achieved by completely separating analysis and code generation.

* /Single-threaded compiler/ — ideally, all CPUs are occupied for the entire compilation. This is not close to true with Rust today. And with the original compiler being single-threaded, the language is not as friendly to parallel compilation as it might be. There are efforts going into parallelizing the compiler, but it may never use all your cores.

* /Trait coherence/ — Rust’s traits have a property called “coherence”, which makes it impossible to define implementations that conflict with each other. Trait coherence imposes restrictions on where code is allowed to live. As such, it is difficult to decompose Rust abstractions into, small, easily-parallelizable compilation units.

* /Tests next to code/ — Rust encourages tests to reside in the same codebase as the code they are testing. With Rust’s compilation model, this requires compiling and linking that code twice, which is expensive, particularly for large crates.

## Recent work on Rust compile times
The situation isn’t hopeless. Not at all. There is always work going on to improve Rust compile times, and there are still many avenues to be explored. I’m hopeful that we’ll continue to see improvements. Here is a selection of the activities I’m aware of from the last year or two. Thanks to everybody who helps with this problem.
* The Rust compile-time  [master issue](https://github.com/rust-lang/rust/issues/48547) 
	* Tracks various work to improve compile times
	* Contains a great overview of factors that affect Rust compilation performance and potential mitigation strategies
* Pipelined compilation (,,)
	* Typechecks downstream crates in parallel with upstream codegen. Now on by default on the stable channel
	* Developed by  [@alexcrichton](https://github.com/alexcrichton)  and  [@nikomatsakis](https://github.com/nikomatsakis) .
* Parallel rustc (,,)
	* Runs analysis phases of the compiler in parallel. Not yet available on the stable channel
	* Developed by  [@Zoxc](https://github.com/Zoxc) ,  [@michaelwoerister](https://github.com/michaelwoerister) ,  [@oli-obk](http://github.com/oli-obk) , and others
*  [MIR-level constant propagation](https://blog.rust-lang.org/inside-rust/2019/12/02/const-prop-on-by-default.html) 
	* Performs constant propagation on MIR, which reduces duplicated LLVM work on monomorphized functions
	* Developed by  [@wesleywiser](https://github.com/wesleywiser) 
*  [MIR optimizations](https://github.com/rust-lang/rust/pulls?q=mir-opt) 
	* Optimizing MIR should be faster than optimizeng monomorphized LLVM IR
	* Not in stable compilers yet
	* Developed by  [@wesleywiser](https://github.com/wesleywiser)  and others
* cargo build -Ztimings (,)
	* Collects and graphs information about cargo’s parallel build timings
	* Developed by  [@ehuss](https://github.com/ehuss)  and  [@luser](https://github.com/luser) 
* rustc -Zself-profile (,,)
	* Generates detailed information about rustc’s internal performance
	* Developed by  [@wesleywiser](https://github.com/wesleywiser)  and  [@michaelwoerister](https://github.com/michaelwoerister) 
*  [Shared monomorphizations](https://github.com/rust-lang/rust/issues/47317) 
	* Reduces code bloat by deduplicating monomorphizations that occur in multiple crates
	* Enabled by default if the optimization level is less than 3.
	* Developed by  [@michaelwoerister](https://github.com/michaelwoerister) 
*  [Cranelift backend](https://www.reddit.com/r/rust/comments/enxgwh/cranelift_backend_for_rust/) 
	* Reduced debug compile times by used  [cranelift](https://github.com/bytecodealliance/cranelift)  for code generation.
	* Developed by  [@bjorn3](https://github.com/bjorn3) 
*  [perf.rust-lang.org](https://perf.rust-lang.org/) 
	* Rust’s compile-time performance is tracked in detail. Benchmarks continue to be added.
	* Developed by [@nrc](https://github.com/nrc) ,  [@Mark-Simulacrum](https://github.com/Mark-Simulacrum) ,  [@nnethercote](https://github.com/nnethercote)  and many more
*  [cargo-bloat](https://github.com/RazrFalcon/cargo-bloat) 
	* Finds what occupies the most space in binaries. Bloat is correlated with compile time
	* Developed by  [@RazrFalcon](https://github.com/RazrFalcon)  and others
*  [cargo-feature-analyst](https://github.com/psinghal20/cargo-feature-analyst) 
	* Finds unused features
	* Developed by  [@psinghal20](https://github.com/psinghal20) 
*  [cargo-udeps](https://github.com/est31/cargo-udeps) 
	* Finds unused crates
	* Developed by  [@est31](https://github.com/est31) 
*  [twiggy](https://github.com/rustwasm/twiggy) 
	* Profiles code size, which is correlated with compile time
	* Developed by  [@fitzgen](https://github.com/fitzgen) ,  [@data-pup](https://github.com/data-pup) , and others
*  [rust-analyzer](https://github.com/rust-analyzer/rust-analyzer) 
	* A new language server for Rust with faster response time than the original  [RLS](https://github.com/rust-lang/rls) 
	* Developed by  [@matklad](https://github.com/matklad) ,  [@flodiebold](https://github.com/flodiebold) ,  [@kjeremy](https://github.com/kjeremy) , and many others
*  [“How to alleviate the pain of Rust compile times”](https://vfoley.xyz/rust-compile-speed-tips/) 
	* Blog post by vfoley
*  [“Thoughts on Rust bloat”](https://raphlinus.github.io/rust/2019/08/21/rust-bloat.html) 
	* Blog post by  [@raphlinus](https://github.com/raphlinus) 
* Nicholas Nethercote’s work on rustc optimization
	*  [“How to speed up the Rust compiler in 2019”](https://blog.mozilla.org/nnethercote/2019/07/17/how-to-speed-up-the-rust-compiler-in-2019/) 
	*  [“The Rust compiler is still getting faster”](https://blog.mozilla.org/nnethercote/2019/07/25/the-rust-compiler-is-still-getting-faster/) 
	*  [“Visualizing Rust compilation”](https://blog.mozilla.org/nnethercote/2019/10/10/visualizing-rust-compilation/) 
	*  [“How to speed up the Rust compiler some more in 2019”](https://blog.mozilla.org/nnethercote/2019/10/11/how-to-speed-up-the-rust-compiler-some-more-in-2019/) 
	*  [“How to speed up the Rust compiler one last time in 2019”](https://blog.mozilla.org/nnethercote/2019/12/11/how-to-speed-up-the-rust-compiler-one-last-time-in-2019/) 
I apologize to any person or project I didn’t credit.
## In the next episode
So Rust dug itself deep into a corner over the years and will probably be digging itself back out until the end of time (or the end of Rust — same thing, really). Can Rust compile-time be saved from Rust’s own run-time success? Will TiKV ever build fast enough to satisfy my managers?
In the next episode, we’ll deep-dive into the specifics of Rust’s language design that cause it to compile slowly.
Stay Rusty, friends.
## Thanks
A number of people helped with this blog series. Thanks especially to Niko Matsakis, Graydon Hoare, and Ted Mielczarek for their insights, and Calvin Weng for proofreading and editing.
## About the author
 [Brian Anderson](https://github.com/brson)  is one of the co-founders of the Rust programming language and its sister project, the Servo web browser. He is now working in PingCAP as a senior database engineer.
